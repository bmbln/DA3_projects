---
title: "Report on Airbnb price prediction in Paris"
author: 'PÃ©ter ENDES-NAGY'
output: 
  pdf_document:
    extra_dependencies: ["float"]
---

```{r setup, include = F}
knitr::opts_chunk$set( echo = FALSE , warning = FALSE , message = FALSE , fig.pos = "!H", out.extra = "")
options(tinytex.verbose = TRUE)
# Set graph size
#knitr::opts_chunk$set(echo = FALSE, out.width = "50%" )#fig.asp = 0.5, fig.width = 7, out.width = "90%" )
#rm(list=ls())

#libraries
library(tidyverse)
library(data.table)
library(modelsummary)
library(caret)
library(knitr)

#
##LOAD CLEAN DATA
data <- read_csv( "https://raw.githubusercontent.com/bmbln/DA3_projects/main/Assignment_2/data/cleaned/paris_listings_clean.csv") %>% 
  mutate_if( is.character, factor )
#holdout and train sets as well
data_holdout <- read_csv( "https://raw.githubusercontent.com/bmbln/DA3_projects/main/Assignment_2/data/cleaned/data_holdout.csv") %>% 
  mutate_if( is.character, factor )
data_train <- read_csv( "https://raw.githubusercontent.com/bmbln/DA3_projects/main/Assignment_2/data/cleaned/data_train.csv") %>% 
  mutate_if( is.character, factor )

##LOAD model results
load( url("https://github.com/bmbln/DA3_projects/blob/main/Assignment_2/data/results/lasso_model.RData?raw=true") )
load( url("https://github.com/bmbln/DA3_projects/blob/main/Assignment_2/data/results/cart_model.RData?raw=true") )
load( url("https://github.com/bmbln/DA3_projects/blob/main/Assignment_2/data/results/rf_model.RData?raw=true") )
load( url("https://github.com/bmbln/DA3_projects/blob/main/Assignment_2/data/results/rf_auto_model.RData?raw=true") )

##LOAD partial dependecy results 
load( url("https://github.com/bmbln/DA3_projects/blob/main/Assignment_2/data/results/dpd.RData?raw=true") )

#functions for descriptive statistics
P95 <- function(x){quantile(x,0.95,na.rm=T)}
P05 <- function(x){quantile(x,0.05,na.rm=T)}
Range <- function(x){max(x,na.rm=T)-min(x,na.rm=T)}

```

## Introduction

This is a report on *predicting Airbnb prices in Paris*. 4 models were built for predicting (log) USD prices for Parisian apartments, based on Airbnb data.  

A LASSO, a CART and 2 random forest models were built - difference in the latter two is autotuning.  
The models were prepared for a client looking forward to list mid-sized (2-6 accommodates) apartments on the Parisian market. 

The data was downloaded for the month of June (2021) that is among the most touristy periods in Paris. The possibilities are open for fine-tuning the models, so they take seasonality into account. 

## Data

Data was downloaded from the Airbnb website [(link here)](http://insideairbnb.com/get-the-data.html) , for the date of 07 June, 2021.  
The raw dataset contained more than 60k observations and 74 variables.   

Raw data was heavily transformed and cleaned before the filtering and meaningful transformations could be carried out. For details on the pre-cleaning, please consult the Technical Documentation available [(here)](https://github.com/bmbln/DA3_projects/blob/main/Assignment_2/DA3_A2_Documentation_ENDES-NAGY.pdf).  

Retrieving and selecting amenities in the listings was the most challenging task. In total, there were 1010 differently worded amenities in the dataset. Only those were kept that appeared in at least 1000 observations: 75 amenity types in total, each stored in binary variables.   

## Data cleaning and feature engineering
Without getting into too many technical details (see more in the Technical Documentation), the potential *predictor variables* were inspected, many of them *simplified/pooled and transformed*. *Missing values* for predictors were mostly imputed with mean/median or a given meaningful value.  

The target variable (price in USD) was transformed into log as it follows lognormal distribution. Extreme values above 2000 USD we discarded, as high-end luxury hotels in Paris are in the 1500-2000 USD range, so up to this value, entire (luxury) flats can be expected in future samples. Listings with 0 USD price were considered missing and discarded from the sample.  

Our client is interested in renting out mid-sized apartments, fit for 2-6 accommodates, so listings out of this range were discarded.  

For the LASSO model, quadratic and cubic forms were introduced for some numerical variables based on loess plots. Interaction terms were also created for the model based on field knowledge.  

At the end, we arrived to a clean and filtered dataset of `r length(data$ln_price)` observations and `r length( colnames( data ) ) ` variables. The key descriptive statistics of the price is as follows: 

```{r price_summary }
datasummary( (`Price (USD)` = n_price) + (`Price (log)` = ln_price) ~ 
             Mean + SD + Median + Min + Max + Range + P05 + P95  , 
             data = data,
             title = 'Prices of Parisian Airbnb listings in June 2021' ) %>% 
  kableExtra::kable_styling(latex_options = "hold_position")
```

## Model building and results 
4 Models were built in total.  

```{r model_results }

final_models <-
  list("LASSO" = lasso_model ,
       "CART" = cart_model ,
       "Random Forest" = rf_model , 
       "Random Forest (autotune)" = rf_model_auto )

results <- resamples(final_models) %>% summary()

cv_results <- imap(final_models, ~{
  mean(results$values[[paste0(.y,"~RMSE")]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("CV RMSE" = ".")

holdout_results <- map( final_models , ~{
  RMSE( predict( .x , newdata = data_holdout ), data_holdout[["ln_price"]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("Holdout RMSE" = ".")

#RMSE values per models
RMSE_per_models <- cbind( cv_results , holdout_results )

lasso_coeffs <- coef( lasso_model$finalModel , lasso_model$bestTune$lambda ) %>%
  as.matrix() %>%
  as.data.frame() %>%
  rownames_to_column( var = "variable" ) %>%
  rename( coefficient = `s1` ) 

# Check the number of variables which actually has coefficients other than 0
lasso_coeffs_nz <- lasso_coeffs %>%
  filter( coefficient != 0 )
```

For the LASSO model, practically all variables were used, as well as quadratic/cubic forms and interactions. As I wasn't interested in building simple OLS models, a LASSO is a straightforward choice, it shrinks the number of variables. The model managed to shrink their number to `r (length(lasso_coeffs_nz$variable)-1)` which is still relatively high. 

For the CART and the 2 Random Forest Models (second one run with autotuning), all available variables were used, except for the quadratic/cubic forms and interactions.

```{r model_summary}
RMSE_per_models %>% 
  mutate_if( is.numeric, format, digits = 4 , nsmall = 0 ) %>% 
  kable( row.names = T , align = "c" ) %>% 
  kableExtra::kable_styling( latex_options = "hold_position")
```
Overall, our best performing model (both on the training, both on the hold out sets) is Random Forest with autotuning, although it didn't lower the RMSE considerably compared to the simple Random Forest model. LASSO was the 3rd performer and CART did the poorest job. 

## Model evaluation
Random Forest models (especially with autotuning) performed the best, so we are going to focus on it during the evaluation. Model performance plots for CART also included in the Annex.  

The biggest disadvantage of Random Forest is that we can't really tell how the given variables are contributing to the predicted value of *price*. We have 2 main ways to identify which features our Clients shall focus on: Variance importance and Partial dependence.  

### Variance importance  
Variance Importance plots show which variables capture the most for our prediction. The following charts display the TOP 15 most influential variables in the autotuned Random Forest model:  

```{r var_imp , fig.align="center" , fig.width=7, fig.height = 5 , out.width="80%"}

rf_model_auto_var_imp <- ranger::importance(rf_model_auto$finalModel)/100
rf_model_auto_var_imp_df <- data.frame( varname = names( rf_model_auto_var_imp ) , imp = rf_model_auto_var_imp ) %>%
  mutate( varname = gsub("^n_", "", varname) ) %>%
  mutate( varname = gsub("^am_", "Amenity: ", varname) ) %>%
  mutate( varname = gsub("^d_", "Dummy: ", varname) ) %>%
  mutate( varname = gsub("^ln_", "Log: ", varname) ) %>%
  mutate( varname = gsub("^f_", "Flag: ", varname) ) %>%
  mutate( varname = gsub("fac_bathrooms", "Number of bathrooms: ", varname) ) %>%
  mutate( varname = gsub("fac_room_type", "Room type: ", varname) ) %>%
  mutate( varname = gsub("fac_host_listings_count", "Host's listings count: ", varname) ) %>%
  mutate( varname = gsub("fac_minimum_nights", "Number of minum nights: ", varname) ) %>%
  mutate( varname = gsub("fac_number_of_reviews", "Number of reviews: ", varname) ) %>%
  mutate( varname = gsub("fac_neighbourhood_cleansed", "Borough: ", varname) ) %>%
  mutate( varname = gsub("fac_property_type", "Property type: ", varname) ) %>%
  arrange( desc( imp ) ) %>% 
  mutate( imp_percentage = imp/sum( imp ) ) %>%
  mutate( rank_pos = c(1:length(imp) ) ) 


ggplot( filter(rf_model_auto_var_imp_df , rank_pos < 15), aes( x = reorder( varname , imp ) , y = imp_percentage ) ) +
  geom_point( color = 'red' , size=1 ) +
  geom_segment( aes( x = varname , xend = varname , y = 0 , yend = imp_percentage ) , color = 'red' , size = .5 ) +
  ylab( "Importance" ) +
  xlab( "Variable Name" ) +
  labs( title = "Variance Importance (Top 15)" , 
        subtitle = "Random Forest model - autotune") +
  coord_flip() +
  scale_y_continuous( expand = c( 0.01 , 0.01 ) , labels = scales::percent_format( accuracy = 1 ) ) +
  theme_bw()
```
The most influential variable in the model is the number of accommodates and the number of bedrooms. Size matters. Number of days elapsed since the first review (implicitly measuring fo how long the apartment had been on the market) is also relatively important, out Client needs to build up their reputation.  

The Client should also pay attention to the reviews, both their score both their numbers, both their timing (recently received) matters.The plot also implies that some rather rare/odd amenities are influential, like dryers and dishwashers. 

Comfort also seem to matter, having more bathrooms than one and having at least one bathroom per bedrooms influences the price.  

## Partial dependence plots
The above mentioned variables influence the prediction, but we don't know how. Partial dependence plots helps us having an idea about them. Partial depence plots were created for almost each TOP 10 variables (see Annex). We should keep in mind, that these variables are highly likely to interact with others - e.g. "private rooms are predicted to have a lower price than shared rooms" sounds very unlikely, they have probably very different features that explains the surprising insight.  
Both the number of accommodates both the number of bedrooms have a positive effect on the price, but the relationship isn't linear, more rooms/accommodates bring less extra revenue.  

The review score is very interesting, until a score of 4 (out of 5), there isn't too much of a difference, but above 4.2, the predicted price increases sharply. Meaning that the Client should pay attention to keep the evaluations at least above 4.2 and keep as high as possible.  

Regarding binary variables, having more than one bathroom increases the price just like the presence of a dishwasher. Interesting enough, if a given property isn't available the upcoming 2-3 months, it has a lower price - unfortunately we can't decide why unavailable. Fully booked or temporally retrieved from the market.  

Entire homes are predicted to be considerably more expensive and apartments with hosts that have more than 5 listings (professionals, like out Clients), the predicted price is almost 25 USD higher.  

## Conslusion
In the report, we investigated Airbnb prices in Paris and built 4 predictive Models for a Client looking forwards to rent out mid-size apartments.  

Among the 4 competing models, CART performed the worst, Random Forest (especially with autotuning) was the most accurate with predicting prices.  

The variable importance and partial dependence plots suggest, that size matters (larger apartments with higher number of accommodates), but not in a linear way. We also see, that potential travelers care about comfort (see importance of having bathrooms for each room) and some special amenities, like dishwasher and dryers. Our Client also needs to build their reputation and pay attention to keep the review scores at least above 4.2, but the higher the better, so they can join the exclusive group of hosts with more that 5 listings, that are also more expensive in Paris.  

# Annex 

## Variance importance plots for CART and Random Forest: 
```{r car_imp}
cart_var_imp <- varImp( cart_model )$importance
cart_var_imp_df <- data.frame( varname = rownames( cart_var_imp ) , imp = cart_var_imp$Overall ) %>%
  mutate( varname = gsub("^n_", "", varname) ) %>%
  mutate( varname = gsub("^am_", "Amenity: ", varname) ) %>%
  mutate( varname = gsub("^d_", "Dummy: ", varname) ) %>%
  mutate( varname = gsub("^ln_", "Log: ", varname) ) %>%
  mutate( varname = gsub("^f_", "Flag: ", varname) ) %>%
  mutate( varname = gsub("fac_bathrooms", "Number of bathrooms: ", varname) ) %>%
  mutate( varname = gsub("fac_room_type", "Room type: ", varname) ) %>%
  mutate( varname = gsub("fac_host_listings_count", "Host's listings count: ", varname) ) %>%
  mutate( varname = gsub("fac_minimum_nights", "Number of minum nights: ", varname) ) %>%
  mutate( varname = gsub("fac_number_of_reviews", "Number of reviews: ", varname) ) %>%
  mutate( varname = gsub("fac_neighbourhood_cleansed", "Borough: ", varname) ) %>%
  mutate( varname = gsub("fac_property_type", "Property type: ", varname) ) %>%
  arrange( desc( imp ) ) %>%
  mutate( imp_percentage = imp/sum( imp ) ) %>% 
  mutate( rank_pos = c(1:length(imp) ) )

ggplot( filter(cart_var_imp_df , imp > 0), aes( x = reorder( varname , imp ) , y = imp_percentage ) ) +
  geom_point( color = 'red' , size=1 ) +
  geom_segment( aes( x = varname , xend = varname , y = 0 , yend = imp_percentage ) , color = 'red' , size = .5 ) +
  ylab( "Importance" ) +
  xlab( "Variable Name" ) +
  labs( title = "Variance Importance" , 
        subtitle = "CART model") +
  coord_flip() +
  scale_y_continuous( expand = c( 0.01 , 0.01 ) , labels = scales::percent_format( accuracy = 1 ) ) +
  theme_bw()



rf_model_var_imp <- ranger::importance(rf_model$finalModel)/100
rf_model_var_imp_df <- data.frame( varname = names( rf_model_var_imp ) , imp = rf_model_var_imp ) %>%
  mutate( varname = gsub("^n_", "", varname) ) %>%
  mutate( varname = gsub("^am_", "Amenity: ", varname) ) %>%
  mutate( varname = gsub("^d_", "Dummy: ", varname) ) %>%
  mutate( varname = gsub("^ln_", "Log: ", varname) ) %>%
  mutate( varname = gsub("^f_", "Flag: ", varname) ) %>%
  mutate( varname = gsub("fac_bathrooms", "Number of bathrooms: ", varname) ) %>%
  mutate( varname = gsub("fac_room_type", "Room type: ", varname) ) %>%
  mutate( varname = gsub("fac_host_listings_count", "Host's listings count: ", varname) ) %>%
  mutate( varname = gsub("fac_minimum_nights", "Number of minum nights: ", varname) ) %>%
  mutate( varname = gsub("fac_number_of_reviews", "Number of reviews: ", varname) ) %>%
  mutate( varname = gsub("fac_neighbourhood_cleansed", "Borough: ", varname) ) %>%
  mutate( varname = gsub("fac_property_type", "Property type: ", varname) ) %>%
  arrange( desc( imp ) ) %>%
  mutate( imp_percentage = imp/sum( imp ) ) %>% 
  mutate( rank_pos = c(1:length(imp) ) )

ggplot( filter( rf_model_var_imp_df , rank_pos < 15), aes( x = reorder( varname , imp ) , y = imp_percentage ) ) +
  geom_point( color = 'red' , size=1 ) +
  geom_segment( aes( x = varname , xend = varname , y = 0 , yend = imp_percentage ) , color = 'red' , size = .5 ) +
  ylab( "Importance" ) +
  xlab( "Variable Name" ) +
  labs( title = "Variance Importance (Top 15)" , 
        subtitle = "Random Forest model") +
  coord_flip() +
  scale_y_continuous( expand = c( 0.01 , 0.01 ) , labels = scales::percent_format( accuracy = 1 ) ) +
  theme_bw()

```

## Partial dependence plots and tables
```{r pdp }
ggplot( pdp_n_acc , aes( n_accommodates , yhat ) ) +
  geom_point( color = 'red' , size = 1 ) +
  geom_line( color = 'red' , size = .5 ) +
  ylab( "Predicted price (USD)" ) +
  xlab( "Accommodates (persons)" ) +
  scale_x_continuous( limit = c ( 2 , 6 ) , breaks = seq( 2 , 6 , 1 ) ) +
  theme_bw()

ggplot(pdp_n_bedrooms , aes( n_bedrooms , yhat ) ) +
  geom_point( color = 'red' , size = 1 ) +
  geom_line( color = 'red' , size = .5 ) +
  ylab( "Predicted price (USD)" ) +
  xlab( "Number of bedrooms" ) +
  scale_x_continuous( limit = c ( 0 , 6 ) , breaks = seq( 0 , 6 , 1 ) ) +
  theme_bw()
 
ggplot(pdp_n_review_scores_rating , aes( n_review_scores_rating , yhat ) ) +
  geom_point( color = 'red' , size = 1 ) +
  geom_line( color = 'red' , size = .5 ) +
  ylab( "Predicted price (USD)" ) +
  xlab( "Review ratings" ) +
  ggtitle( "Partial dependence plot: Review scores") +
  scale_x_continuous( limit = c ( 0 , 5 ) , breaks = seq( 0 , 5 , 1 ) ) +
  theme_bw()

ggplot(pdp_fac_room_type , aes( fac_room_type , yhat ) ) +
  geom_point( color = 'red' , size = 3 ) +
  ylab( "Predicted price (USD)" ) +
  xlab( "Room type" ) +
  scale_y_continuous( limits = c( 70 , 110 ), breaks = seq( 70 , 100 , by = 10 ) ) +
  theme_bw()

ggplot(pdp_fac_host_listings_count , aes( fac_host_listings_count , yhat ) ) +
  geom_point( color = 'red' , size = 3 ) +
  ylab( "Predicted price (USD)" ) +
  xlab( "Host has more listings" ) +
  scale_y_continuous( limits = c( 80 , 130  ), breaks = seq( 80 , 130 , by = 10 ) ) +
  theme_bw()
```

Partial dependence table with predicted mean prices for the binary variables:

```{r pdp_binary_table}
#binaries together in a table 
pdp_binary <- cbind( pdp_d_more_bathrooms , pdp_d_unavailable_31_90 , pdp_am_dishwasher )[c(1,2,4,6)]
colnames(pdp_binary) <- c(" " , "More than one bathrooms","Unavailable for the upcoming months","Amenity: Dishwasher")
pdp_binary[1] <-  c("No","Yes")


pdp_binary %>% 
  mutate_if( is.numeric, format, digits = 2 , nsmall = 0 ) %>% 
  kable( row.names = F , align = "c" ) %>% 
  kableExtra::kable_styling( latex_options = "hold_position")
```



